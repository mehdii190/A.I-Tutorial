import gymimport randomimport numpy as npimport time########################3env = gym.make("FrozenLake-v1", desc=None , map_name="4x4", is_slippery=False, render_mode="ansi")action_size = env.action_space.nstate_size = env.observation_space.nqtable = np.zeros((state_size,action_size))print("Init Qtable:\n ")print(qtable)total_episodes = 300learning_rate = 0.8max_steps = 20gamma = 0.5#env.reset()#env.render()#time.sleep(5)#env.close()#############print("training....")for episode in range(total_episodes):    state = env.reset()[0]    step = 0    done = False    print("episode: ",episode)    for step in range(max_steps):        action = env.action_space.sample()        env.render()        new_state , reward, done , truncated , info = env.step(action)        if done and reward == 0 :            reward = -5        if new_state == state:            reward = -1                print("new state: ",new_state,"reward: ",reward)                qtable[state,action]=reward-gamma*np.max(qtable[new_state, :])        print("qtable at : ",state,qtable[state])        state = new_state        if done:            print("GAME OVER. \n\n")            break            print("new QTABLE: ")    print(qtable)    env.reset()env.close()print("ok result is  going on")#######################print("new env is running......")env = gym.make("FrozenLake-v1", desc=None , map_name="4x4", is_slippery=False, render_mode="human")state = env.reset()[0]step = 0done = Falseprint("***********************************")for step in range(max_steps):    env.render()    action = np.argmax(qtable[state,:])    new_state , reward, done,truncated,info = env.step(action)    if done:        break    state = new_state    time.sleep(5)env.close()print("end...")                                                                                                                                                                                                